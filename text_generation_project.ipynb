{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Vijay\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "#import dependencies\n",
    "import numpy\n",
    "import sys\n",
    "import nltk\n",
    "nltk.download('stopwords')\n",
    "from nltk.tokenize import RegexpTokenizer\n",
    "from nltk.corpus import stopwords\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Dropout, LSTM\n",
    "from keras.utils import np_utils\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "file = open(\"frankenstein-2.txt\", encoding=\"utf8\").read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#tokenize the text\n",
    "# if the created token isn't in the stop words, make it part of \"filtered\"\n",
    "def tokenize_words(input):\n",
    "    input = input.lower()\n",
    "    tokenizer = RegexpTokenizer(r'\\w+')\n",
    "    tokens = tokenizer.tokenize(input)\n",
    "    filtered = filter(lambda token: token not in stopwords.words('english'), tokens)\n",
    "    return \" \".join(filtered)\n",
    "processed_inputs = tokenize_words(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting charecters into numbers\n",
    "chars = sorted(list(set(processed_inputs)))\n",
    "char_to_num = dict((c, i) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of characters: 269995\n",
      "Total vocab: 43\n"
     ]
    }
   ],
   "source": [
    "#checking the total number of charecters and different types of vocabularies\n",
    "input_len = len(processed_inputs)\n",
    "vocab_len = len(chars)\n",
    "print (\"Total number of characters:\", input_len)\n",
    "print (\"Total vocab:\", vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#defining lenght of an induvidual sequence\n",
    "seq_length = 100\n",
    "x_data = []\n",
    "y_data = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total Patterns: 269895\n"
     ]
    }
   ],
   "source": [
    "#creating sequences\n",
    "for i in range(0, input_len - seq_length, 1):\n",
    "    in_seq = processed_inputs[i:i + seq_length]\n",
    "\n",
    "    out_seq = processed_inputs[i + seq_length]\n",
    "\n",
    "    x_data.append([char_to_num[char] for char in in_seq])\n",
    "    y_data.append(char_to_num[out_seq])\n",
    "\n",
    "n_patterns = len(x_data)\n",
    "print (\"Total Patterns:\", n_patterns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#converting into an numpy array\n",
    "X = numpy.reshape(x_data, (n_patterns, seq_length, 1))\n",
    "X = X/float(vocab_len)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot-encoding\n",
    "y = np_utils.to_categorical(y_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#dropuout to prevent overfitting\n",
    "model = Sequential()\n",
    "model.add(LSTM(256, input_shape=(X.shape[1], X.shape[2]), return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(256, return_sequences=True))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(LSTM(128))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Dense(y.shape[1], activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "#model compilation\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#setting a checkpoint since the model takes quite a while to train\n",
    "filepath = \"model_weights_saved.hdf5\"\n",
    "checkpoint = ModelCheckpoint(filepath, monitor='loss', verbose=1, save_best_only=True, mode='min')\n",
    "desired_callbacks = [checkpoint]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for 4 epochs and a batch_size of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/4\n",
      "1055/1055 [==============================] - ETA: 0s - loss: 2.9140\n",
      "Epoch 00001: loss improved from inf to 2.91398, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 72s 68ms/step - loss: 2.9140\n",
      "Epoch 2/4\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.6558\n",
      "Epoch 00002: loss improved from 2.91398 to 2.65575, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 2.6558\n",
      "Epoch 3/4\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.5245\n",
      "Epoch 00003: loss improved from 2.65575 to 2.52454, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 2.5245\n",
      "Epoch 4/4\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.4089\n",
      "Epoch 00004: loss improved from 2.52454 to 2.40894, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 76s 72ms/step - loss: 2.4089\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22d9fd0b0c8>"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=4, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recompile model with saved weights\n",
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output of the model back into charecters\n",
    "num_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:\n",
      "\" es much tranquillise mind steady purpose point soul may fix intellectual eye expedition favourite dr \"\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed:\")\n",
    "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eated seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare seare sear"
     ]
    }
   ],
   "source": [
    "#generate the text\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "\n",
    "    sys.stdout.write(result)\n",
    "\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## for 60 epochs and a batch_size of 256"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.3117\n",
      "Epoch 00001: loss improved from 2.40894 to 2.31170, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 72s 68ms/step - loss: 2.3117\n",
      "Epoch 2/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.2357\n",
      "Epoch 00002: loss improved from 2.31170 to 2.23569, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 2.2357\n",
      "Epoch 3/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.1720\n",
      "Epoch 00003: loss improved from 2.23569 to 2.17204, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 2.1720\n",
      "Epoch 4/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.1146\n",
      "Epoch 00004: loss improved from 2.17204 to 2.11460, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 2.1146\n",
      "Epoch 5/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.0635\n",
      "Epoch 00005: loss improved from 2.11460 to 2.06350, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 2.0635\n",
      "Epoch 6/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 2.0236\n",
      "Epoch 00006: loss improved from 2.06350 to 2.02359, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 2.0236\n",
      "Epoch 7/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.9853\n",
      "Epoch 00007: loss improved from 2.02359 to 1.98524, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.9852\n",
      "Epoch 8/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.9541\n",
      "Epoch 00008: loss improved from 1.98524 to 1.95415, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.9541\n",
      "Epoch 9/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.9270\n",
      "Epoch 00009: loss improved from 1.95415 to 1.92704, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.9270\n",
      "Epoch 10/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.9023\n",
      "Epoch 00010: loss improved from 1.92704 to 1.90228, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.9023\n",
      "Epoch 11/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.8821\n",
      "Epoch 00011: loss improved from 1.90228 to 1.88217, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.8822\n",
      "Epoch 12/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.8615\n",
      "Epoch 00012: loss improved from 1.88217 to 1.86146, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.8615\n",
      "Epoch 13/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.8399\n",
      "Epoch 00013: loss improved from 1.86146 to 1.83986, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.8399\n",
      "Epoch 14/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.8259\n",
      "Epoch 00014: loss improved from 1.83986 to 1.82592, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.8259\n",
      "Epoch 15/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.8090\n",
      "Epoch 00015: loss improved from 1.82592 to 1.80902, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.8090\n",
      "Epoch 16/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7965\n",
      "Epoch 00016: loss improved from 1.80902 to 1.79664, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.7966\n",
      "Epoch 17/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7816\n",
      "Epoch 00017: loss improved from 1.79664 to 1.78153, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.7815\n",
      "Epoch 18/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7686\n",
      "Epoch 00018: loss improved from 1.78153 to 1.76864, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.7686\n",
      "Epoch 19/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7601\n",
      "Epoch 00019: loss improved from 1.76864 to 1.76001, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.7600\n",
      "Epoch 20/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7469\n",
      "Epoch 00020: loss improved from 1.76001 to 1.74694, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.7469\n",
      "Epoch 21/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7375\n",
      "Epoch 00021: loss improved from 1.74694 to 1.73755, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.7375\n",
      "Epoch 22/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7271\n",
      "Epoch 00022: loss improved from 1.73755 to 1.72706, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.7271\n",
      "Epoch 23/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7181\n",
      "Epoch 00023: loss improved from 1.72706 to 1.71807, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.7181\n",
      "Epoch 24/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7105\n",
      "Epoch 00024: loss improved from 1.71807 to 1.71049, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.7105\n",
      "Epoch 25/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.7016\n",
      "Epoch 00025: loss improved from 1.71049 to 1.70155, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.7016\n",
      "Epoch 26/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6976\n",
      "Epoch 00026: loss improved from 1.70155 to 1.69768, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6977\n",
      "Epoch 27/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6867\n",
      "Epoch 00027: loss improved from 1.69768 to 1.68660, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6866\n",
      "Epoch 28/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6777\n",
      "Epoch 00028: loss improved from 1.68660 to 1.67773, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6777\n",
      "Epoch 29/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6758\n",
      "Epoch 00029: loss improved from 1.67773 to 1.67581, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6758\n",
      "Epoch 30/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6676\n",
      "Epoch 00030: loss improved from 1.67581 to 1.66754, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.6675\n",
      "Epoch 31/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6620\n",
      "Epoch 00031: loss improved from 1.66754 to 1.66201, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6620\n",
      "Epoch 32/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6585\n",
      "Epoch 00032: loss improved from 1.66201 to 1.65835, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.6583\n",
      "Epoch 33/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6526\n",
      "Epoch 00033: loss improved from 1.65835 to 1.65259, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6526\n",
      "Epoch 34/60\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6441\n",
      "Epoch 00034: loss improved from 1.65259 to 1.64417, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6442\n",
      "Epoch 35/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6403\n",
      "Epoch 00035: loss improved from 1.64417 to 1.64037, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6404\n",
      "Epoch 36/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6354\n",
      "Epoch 00036: loss improved from 1.64037 to 1.63535, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6354\n",
      "Epoch 37/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6311\n",
      "Epoch 00037: loss improved from 1.63535 to 1.63110, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6311\n",
      "Epoch 38/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6262\n",
      "Epoch 00038: loss improved from 1.63110 to 1.62621, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6262\n",
      "Epoch 39/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6221\n",
      "Epoch 00039: loss improved from 1.62621 to 1.62205, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6220\n",
      "Epoch 40/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6161\n",
      "Epoch 00040: loss improved from 1.62205 to 1.61611, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6161\n",
      "Epoch 41/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6132\n",
      "Epoch 00041: loss improved from 1.61611 to 1.61325, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6132\n",
      "Epoch 42/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6099\n",
      "Epoch 00042: loss improved from 1.61325 to 1.60995, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6099\n",
      "Epoch 43/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6054\n",
      "Epoch 00043: loss improved from 1.60995 to 1.60541, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6054\n",
      "Epoch 44/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.6012\n",
      "Epoch 00044: loss improved from 1.60541 to 1.60124, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.6012\n",
      "Epoch 45/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5970\n",
      "Epoch 00045: loss improved from 1.60124 to 1.59701, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.5970\n",
      "Epoch 46/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5929\n",
      "Epoch 00046: loss improved from 1.59701 to 1.59298, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5930\n",
      "Epoch 47/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5898\n",
      "Epoch 00047: loss improved from 1.59298 to 1.58975, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5897\n",
      "Epoch 48/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5869\n",
      "Epoch 00048: loss improved from 1.58975 to 1.58687, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5869\n",
      "Epoch 49/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5828\n",
      "Epoch 00049: loss improved from 1.58687 to 1.58278, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.5828\n",
      "Epoch 50/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5784\n",
      "Epoch 00050: loss improved from 1.58278 to 1.57848, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5785\n",
      "Epoch 51/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5774\n",
      "Epoch 00051: loss improved from 1.57848 to 1.57749, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5775\n",
      "Epoch 52/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5726\n",
      "Epoch 00052: loss improved from 1.57749 to 1.57260, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.5726\n",
      "Epoch 53/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5678\n",
      "Epoch 00053: loss improved from 1.57260 to 1.56793, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5679\n",
      "Epoch 54/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5669\n",
      "Epoch 00054: loss improved from 1.56793 to 1.56690, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5669\n",
      "Epoch 55/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5655\n",
      "Epoch 00055: loss improved from 1.56690 to 1.56544, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 71ms/step - loss: 1.5654\n",
      "Epoch 56/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5635\n",
      "Epoch 00056: loss improved from 1.56544 to 1.56352, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5635\n",
      "Epoch 57/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5603\n",
      "Epoch 00057: loss improved from 1.56352 to 1.56025, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 75s 71ms/step - loss: 1.5603\n",
      "Epoch 58/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5557\n",
      "Epoch 00058: loss improved from 1.56025 to 1.55571, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5557\n",
      "Epoch 59/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5549\n",
      "Epoch 00059: loss improved from 1.55571 to 1.55485, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5549\n",
      "Epoch 60/60\n",
      "1054/1055 [============================>.] - ETA: 0s - loss: 1.5511\n",
      "Epoch 00060: loss improved from 1.55485 to 1.55105, saving model to model_weights_saved.hdf5\n",
      "1055/1055 [==============================] - 74s 70ms/step - loss: 1.5511\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x22de8c65948>"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, epochs=60, batch_size=256, callbacks=desired_callbacks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "#recompile model with saved weights\n",
    "filename = \"model_weights_saved.hdf5\"\n",
    "model.load_weights(filename)\n",
    "model.compile(loss='categorical_crossentropy', optimizer='adam')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "# output of the model back into charecters\n",
    "num_to_char = dict((i, c) for i, c in enumerate(chars))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Seed:\n",
      "\" ife one turnkeys countenance expressed bad qualities often characterise class lines face hard rude l \"\n"
     ]
    }
   ],
   "source": [
    "start = numpy.random.randint(0, len(x_data) - 1)\n",
    "pattern = x_data[start]\n",
    "print(\"Random Seed:\")\n",
    "print(\"\\\"\", ''.join([num_to_char[value] for value in pattern]), \"\\\"\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see see"
     ]
    }
   ],
   "source": [
    "#generate the text\n",
    "for i in range(1000):\n",
    "    x = numpy.reshape(pattern, (1, len(pattern), 1))\n",
    "    x = x / float(vocab_len)\n",
    "    prediction = model.predict(x, verbose=0)\n",
    "    index = numpy.argmax(prediction)\n",
    "    result = num_to_char[index]\n",
    "    seq_in = [num_to_char[value] for value in pattern]\n",
    "\n",
    "    sys.stdout.write(result)\n",
    "\n",
    "    pattern.append(index)\n",
    "    pattern = pattern[1:len(pattern)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
